<!DOCTYPE html>
<html lang="en">
<head>
   <meta charset="UTF-8">
   <meta name="viewport" content="width=device-width, initial-scale=1.0">
   <title>Speech Analysis - AI Speech Therapist</title>
   <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">
   <style>
       body {
           font-family: 'Poppins', sans-serif;
           margin: 0;
           padding: 0;
           background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
           min-height: 100vh;
       }


       .container {
           max-width: 800px;
           margin: 0 auto;
           padding: 2rem;
       }


       .analysis-section {
           background: white;
           padding: 2rem;
           border-radius: 10px;
           box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
           margin-bottom: 2rem;
       }


       .record-button {
           display: inline-block;
           padding: 1rem 2rem;
           background-color: #3498db;
           color: white;
           border: none;
           border-radius: 30px;
           font-weight: 500;
           cursor: pointer;
           transition: all 0.3s ease;
       }


       .record-button:hover {
           background-color: #2980b9;
       }


       .record-button.recording {
           background-color: #e74c3c;
       }


       #transcription, #feedback {
           margin-top: 1rem;
           padding: 1rem;
           background: #f8f9fa;
           border-radius: 5px;
           min-height: 100px;
       }


       .status {
           color: #7f8c8d;
           margin-top: 0.5rem;
       }


       .button-group {
           display: flex;
           gap: 1rem;
           margin-bottom: 1rem;
       }


       .play-button {
           display: inline-block;
           padding: 1rem 2rem;
           background-color: #27ae60;
           color: white;
           border: none;
           border-radius: 30px;
           font-weight: 500;
           cursor: pointer;
           transition: all 0.3s ease;
       }


       .play-button:hover {
           background-color: #219a52;
       }


       .play-button:disabled {
           background-color: #bdc3c7;
           cursor: not-allowed;
       }


       .audio-player {
           margin-top: 1rem;
           width: 100%;
       }
   </style>
</head>
<body>
   <div class="container">
       <div class="analysis-section">
           <h2>Speech Analysis</h2>
           <div class="button-group">
               <button id="recordButton" class="record-button">Start Recording</button>
               <button id="playButton" class="play-button" disabled>Play Recording</button>
           </div>
           <p class="status" id="status">Click to start recording</p>
          
           <audio id="audioPlayback" class="audio-player" controls style="display: none;"></audio>
          
           <h3>Your Speech</h3>
           <div id="transcription">Transcription will appear here...</div>
          
           <h3>AI Feedback</h3>
           <div id="feedback">Feedback will appear here...</div>
       </div>
   </div>


   <script>
       let mediaRecorder;
       let audioChunks = [];
       let audioUrl;
      
       const recordButton = document.getElementById('recordButton');
       const playButton = document.getElementById('playButton');
       const status = document.getElementById('status');
       const audioPlayback = document.getElementById('audioPlayback');
       const transcriptionDiv = document.getElementById('transcription');
       const feedbackDiv = document.getElementById('feedback');


       recordButton.addEventListener('click', async () => {
           if (mediaRecorder && mediaRecorder.state === 'recording') {
               mediaRecorder.stop();
               recordButton.textContent = 'Start Recording';
               recordButton.classList.remove('recording');
               status.textContent = 'Processing...';
           } else {
               try {
                   // Request high-quality audio
                   const stream = await navigator.mediaDevices.getUserMedia({ 
                       audio: {
                           channelCount: 1,
                           sampleRate: 16000,
                           echoCancellation: true,
                           noiseSuppression: true,
                           autoGainControl: true
                       }
                   });
                   
                   // Clear previous recording
                   audioChunks = [];
                   
                   // Create MediaRecorder with specific settings
                   mediaRecorder = new MediaRecorder(stream, {
                       mimeType: 'audio/webm;codecs=opus',
                       audioBitsPerSecond: 128000 // Increase bit rate
                   });
                   
                   mediaRecorder.ondataavailable = (event) => {
                       if (event.data.size > 0) {
                           audioChunks.push(event.data);
                           console.log('Audio chunk received:', event.data.size, 'bytes');
                       }
                   };

                   mediaRecorder.onstop = () => {
                       // Stop the stream tracks
                       stream.getTracks().forEach(track => track.stop());
                       
                       console.log('Recording stopped');
                       console.log('Total chunks:', audioChunks.length);

                       // Create audio blob
                       const audioBlob = new Blob(audioChunks, { 
                           type: 'audio/webm;codecs=opus'
                       });
                       console.log('Blob created, size:', audioBlob.size);

                       // Clean up old audio URL
                       if (audioUrl) {
                           URL.revokeObjectURL(audioUrl);
                       }

                       // Set up audio playback
                       audioUrl = URL.createObjectURL(audioBlob);
                       audioPlayback.src = audioUrl;
                       audioPlayback.style.display = 'block';
                       playButton.disabled = false;

                       // Test playback
                       audioPlayback.load();
                       audioPlayback.onloadeddata = () => {
                           console.log('Audio loaded, duration:', audioPlayback.duration);
                           status.textContent = 'Recording ready for playback';
                       };

                       // Send for analysis
                       const reader = new FileReader();
                       reader.onloadend = async () => {
                           try {
                               status.textContent = 'Sending to server...';
                               const response = await fetch('http://127.0.0.1:3000/api/analyze-speech', {
                                   method: 'POST',
                                   headers: { 'Content-Type': 'application/json' },
                                   body: JSON.stringify({
                                       audio: reader.result,
                                       referenceText: "This is a test."
                                   })
                               });

                               const results = await response.json();
                               console.log('Analysis results:', results);
                               
                               transcriptionDiv.textContent = results.transcription || 'No transcription';
                               feedbackDiv.textContent = results.feedback || 'No feedback';
                               status.textContent = 'Analysis complete';
                           } catch (error) {
                               console.error('Server error:', error);
                               status.textContent = 'Server error: ' + error.message;
                           }
                       };

                       reader.readAsDataURL(audioBlob);
                   };

                   // Start recording in smaller chunks
                   mediaRecorder.start(100);
                   recordButton.textContent = 'Stop Recording';
                   recordButton.classList.add('recording');
                   status.textContent = 'Recording... (speak clearly)';

               } catch (error) {
                   console.error('Recording error:', error);
                   status.textContent = 'Error: ' + error.message;
               }
           }
       });

       // Make sure audio controls work
       audioPlayback.onplay = () => {
           playButton.textContent = 'Pause';
           console.log('Audio playing');
       };

       audioPlayback.onpause = () => {
           playButton.textContent = 'Play Recording';
           console.log('Audio paused');
       };

       playButton.onclick = () => {
           if (audioPlayback.paused) {
               audioPlayback.play();
           } else {
               audioPlayback.pause();
           }
       };
   </script>

   <script>
       // Helper function to write strings to DataView
       function writeString(view, offset, string) {
           for (let i = 0; i < string.length; i++) {
               view.setUint8(offset + i, string.charCodeAt(i));
           }
       }
   </script>
</body>
</html>
