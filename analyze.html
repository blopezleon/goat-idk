<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Analysis - AI Speech Therapist</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
        }

        .analysis-section {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 2rem;
        }

        .record-button {
            display: inline-block;
            padding: 1rem 2rem;
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 30px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .record-button:hover {
            background-color: #2980b9;
        }

        .record-button.recording {
            background-color: #e74c3c;
        }

        #transcription, #feedback {
            margin-top: 1rem;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 5px;
            min-height: 100px;
        }

        .status {
            color: #7f8c8d;
            margin-top: 0.5rem;
        }

        .button-group {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
        }

        .play-button {
            display: inline-block;
            padding: 1rem 2rem;
            background-color: #27ae60;  /* Green color for play button */
            color: white;
            border: none;
            border-radius: 30px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .play-button:hover {
            background-color: #219a52;
        }

        .play-button:disabled {
            background-color: #bdc3c7;
            cursor: not-allowed;
        }

        .audio-player {
            margin-top: 1rem;
            width: 100%;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="analysis-section">
            <h2>Speech Analysis</h2>
            <div class="button-group">
                <button id="recordButton" class="record-button">Start Recording</button>
                <button id="playButton" class="play-button" disabled>Play Recording</button>
            </div>
            <p class="status" id="status">Click to start recording</p>
            
            <audio id="audioPlayback" class="audio-player" controls style="display: none;"></audio>
            
            <h3>Your Speech</h3>
            <div id="transcription">Transcription will appear here...</div>
            
            <h3>AI Feedback</h3>
            <div id="feedback">Feedback will appear here...</div>

            <h3>Raw Analysis Data</h3>
            <pre id="rawData" style="background: #f8f9fa; padding: 1rem; border-radius: 5px; overflow-x: auto;">
                Raw analysis data will appear here...
            </pre>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        const recordButton = document.getElementById('recordButton');
        const playButton = document.getElementById('playButton');
        const status = document.getElementById('status');
        const transcriptionDiv = document.getElementById('transcription');
        const feedbackDiv = document.getElementById('feedback');
        const audioPlayback = document.getElementById('audioPlayback');

        recordButton.addEventListener('click', async () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                recordButton.textContent = 'Start Recording';
                recordButton.classList.remove('recording');
                status.textContent = 'Processing...';
            } else {
                // Reset audio
                audioChunks = [];
                audioBlob = null;
                audioPlayback.style.display = 'none';
                playButton.disabled = true;

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    
                    // Enable playback
                    const audioUrl = URL.createObjectURL(audioBlob);
                    audioPlayback.src = audioUrl;
                    audioPlayback.style.display = 'block';
                    playButton.disabled = false;

                    await analyzeAudio(audioBlob);
                };

                mediaRecorder.start();
                recordButton.textContent = 'Stop Recording';
                recordButton.classList.add('recording');
                status.textContent = 'Recording...';
            }
        });

        playButton.addEventListener('click', () => {
            if (audioPlayback.paused) {
                audioPlayback.play();
                playButton.textContent = 'Pause';
            } else {
                audioPlayback.pause();
                playButton.textContent = 'Play Recording';
            }
        });

        // Update play button text when audio ends
        audioPlayback.addEventListener('ended', () => {
            playButton.textContent = 'Play Recording';
        });

        // Update play button text when audio is paused
        audioPlayback.addEventListener('pause', () => {
            playButton.textContent = 'Play Recording';
        });

        // Update play button text when audio is playing
        audioPlayback.addEventListener('play', () => {
            playButton.textContent = 'Pause';
        });

        async function analyzeAudio(audioBlob) {
            try {
                status.textContent = 'Sending audio for analysis...';
                
                // Use relative paths instead of absolute URLs
                try {
                    const testResponse = await fetch('/test', {
                        mode: 'cors'
                    });
                    if (!testResponse.ok) {
                        throw new Error('Server is not responding');
                    }
                } catch (error) {
                    throw new Error('Cannot connect to server. Please try again.');
                }

                const reader = new FileReader();
                
                reader.onloadend = async () => {
                    try {
                        const base64Audio = reader.result;
                        console.log('Sending audio data to server...');
                        
                        const response = await fetch('/api/analyze-speech', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json',
                            },
                            mode: 'cors',
                            body: JSON.stringify({
                                audio: base64Audio,
                                referenceText: "This is a test."
                            })
                        });

                        if (!response.ok) {
                            const errorText = await response.text();
                            throw new Error(`Server error (${response.status}): ${errorText}`);
                        }

                        const results = await response.json();
                        console.log('Received results:', results);
                        
                        if (results.error) {
                            throw new Error(results.error);
                        }

                        // Display transcription
                        transcriptionDiv.textContent = results.transcription || 'No transcription available';

                        // Generate and display feedback
                        let feedback = `Overall Assessment:\n`;
                        feedback += `------------------------\n`;
                        feedback += `Pronunciation Score: ${results.scores.pronunciation}%\n`;
                        feedback += `Accuracy Score: ${results.scores.accuracy}%\n`;
                        feedback += `Fluency Score: ${results.scores.fluency}%\n`;
                        feedback += `Completeness Score: ${results.scores.completeness}%\n`;
                        
                        if (results.words && results.words.length > 0) {
                            feedback += `\nWord-by-word Analysis:\n`;
                            feedback += `------------------------\n`;
                            results.words.forEach(word => {
                                feedback += `Word: "${word.Word}"\n`;
                                feedback += `  - Accuracy: ${word.PronunciationAssessment?.AccuracyScore}%\n`;
                                feedback += `  - Error Type: ${word.PronunciationAssessment?.ErrorType}\n`;
                                if (word.PronunciationAssessment?.ErrorType !== 'None') {
                                    feedback += `  - Suggestion: Practice this word more carefully\n`;
                                }
                                feedback += `\n`;
                            });
                        }

                        feedbackDiv.innerHTML = feedback.replace(/\n/g, '<br>');
                        
                        // Display raw data
                        document.getElementById('rawData').textContent = 
                            JSON.stringify(results, null, 2);

                        status.textContent = 'Analysis complete';
                    } catch (error) {
                        console.error('Error during analysis:', error);
                        status.textContent = `Error: ${error.message}`;
                        feedbackDiv.innerHTML = `Error analyzing speech: ${error.message}`;
                    }
                };

                reader.onerror = (error) => {
                    console.error('Error reading audio file:', error);
                    status.textContent = 'Error reading audio file';
                };

                reader.readAsDataURL(audioBlob);
            } catch (error) {
                console.error('Error in analyzeAudio:', error);
                status.textContent = `Error: ${error.message}`;
            }
        }
    </script>
</body>
</html>
