<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech Analysis - AI Speech Therapist</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
        }

        .analysis-section {
            background: white;
            padding: 2rem;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 2rem;
        }

        .record-button {
            display: inline-block;
            padding: 1rem 2rem;
            background-color: #3498db;
            color: white;
            border: none;
            border-radius: 30px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .record-button:hover {
            background-color: #2980b9;
        }

        .record-button.recording {
            background-color: #e74c3c;
        }

        #transcription, #feedback {
            margin-top: 1rem;
            padding: 1rem;
            background: #f8f9fa;
            border-radius: 5px;
            min-height: 100px;
        }

        .status {
            color: #7f8c8d;
            margin-top: 0.5rem;
        }

        .button-group {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
        }

        .play-button {
            display: inline-block;
            padding: 1rem 2rem;
            background-color: #27ae60;  /* Green color for play button */
            color: white;
            border: none;
            border-radius: 30px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .play-button:hover {
            background-color: #219a52;
        }

        .play-button:disabled {
            background-color: #bdc3c7;
            cursor: not-allowed;
        }

        .audio-player {
            margin-top: 1rem;
            width: 100%;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="analysis-section">
            <h2>Speech Analysis</h2>
            <div class="button-group">
                <button id="recordButton" class="record-button">Start Recording</button>
                <button id="playButton" class="play-button" disabled>Play Recording</button>
            </div>
            <p class="status" id="status">Click to start recording</p>
            
            <audio id="audioPlayback" class="audio-player" controls style="display: none;"></audio>
            
            <h3>Your Speech</h3>
            <div id="transcription">Transcription will appear here...</div>
            
            <h3>AI Feedback</h3>
            <div id="feedback">Feedback will appear here...</div>

            <h3>Raw Analysis Data</h3>
            <pre id="rawData" style="background: #f8f9fa; padding: 1rem; border-radius: 5px; overflow-x: auto;">
                Raw analysis data will appear here...
            </pre>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob = null;
        const recordButton = document.getElementById('recordButton');
        const playButton = document.getElementById('playButton');
        const status = document.getElementById('status');
        const transcriptionDiv = document.getElementById('transcription');
        const feedbackDiv = document.getElementById('feedback');
        const audioPlayback = document.getElementById('audioPlayback');

        recordButton.addEventListener('click', async () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                recordButton.textContent = 'Start Recording';
                recordButton.classList.remove('recording');
                status.textContent = 'Processing...';
            } else {
                try {
                    audioChunks = [];
                    audioBlob = null;
                    audioPlayback.style.display = 'none';
                    playButton.disabled = true;

                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            channelCount: 1,
                            sampleRate: 16000,
                            sampleSize: 16,
                            volume: 1
                        }
                    });

                    mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus',
                        audioBitsPerSecond: 16000
                    });

                    mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };

                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                        
                        // Convert to WAV format
                        const audioUrl = URL.createObjectURL(audioBlob);
                        audioPlayback.src = audioUrl;
                        audioPlayback.style.display = 'block';
                        playButton.disabled = false;

                        // Stop all tracks
                        stream.getTracks().forEach(track => track.stop());

                        await analyzeAudio(audioBlob);
                    };

                    mediaRecorder.start();
                    recordButton.textContent = 'Stop Recording';
                    recordButton.classList.add('recording');
                    status.textContent = 'Recording...';
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    status.textContent = 'Error accessing microphone';
                }
            }
        });

        playButton.addEventListener('click', () => {
            if (audioPlayback.paused) {
                audioPlayback.play();
                playButton.textContent = 'Pause';
            } else {
                audioPlayback.pause();
                playButton.textContent = 'Play Recording';
            }
        });

        // Update play button text when audio ends
        audioPlayback.addEventListener('ended', () => {
            playButton.textContent = 'Play Recording';
        });

        // Update play button text when audio is paused
        audioPlayback.addEventListener('pause', () => {
            playButton.textContent = 'Play Recording';
        });

        // Update play button text when audio is playing
        audioPlayback.addEventListener('play', () => {
            playButton.textContent = 'Pause';
        });

        async function analyzeAudio(audioBlob) {
            try {
                // Convert audio blob to base64
                const reader = new FileReader();
                
                reader.onloadend = async () => {
                    const base64Audio = reader.result;
                    
                    // Send to server for analysis
                    const response = await fetch('http://localhost:3000/api/analyze-speech', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            audio: base64Audio,
                            referenceText: "This is a test." // You can make this dynamic based on what you want the user to say
                        })
                    });

                        const results = await response.json();
                        console.log('Received results:', results);
                        
                        if (results.error) {
                            throw new Error(results.error);
                        }

                    // Display transcription
                    transcriptionDiv.textContent = results.transcription;

                    // Generate and display feedback
                    let feedback = `Overall Pronunciation Score: ${results.scores.pronunciation}\n\n`;
                    feedback += `Accuracy: ${results.scores.accuracy}%\n`;
                    feedback += `Fluency: ${results.scores.fluency}%\n`;
                    feedback += `Completeness: ${results.scores.completeness}%\n\n`;
                    
                    feedback += "Word-by-word analysis:\n";
                    results.words.forEach(word => {
                        feedback += `${word.Word}: ${word.PronunciationAssessment.AccuracyScore}% accuracy\n`;
                    });

                    feedbackDiv.innerHTML = feedback.replace(/\n/g, '<br>');
                    status.textContent = 'Analysis complete';
                };
            } catch (error) {
                status.textContent = 'Error analyzing speech';
                console.error(error);
            }
        }
    </script>
</body>
</html>
